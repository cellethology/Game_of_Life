"""
Optimized weight experiment based on your clear suggestions.

This implements:
1. Direct analysis of existing datasets
2. Automatic computation of optimal weights for each density
3. Clean comparison of weighted vs unweighted models
4. Systematic testing across configurations
"""

import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
import pandas as pd
from pathlib import Path
import sys
import subprocess
import time

try:
    from .data import LifePatchDataset, generate_life_patch_dataset
    from .models import MLP
    from .confusion_matrix_utils import compute_confusion_entries, save_confusion_matrix_to_csv
except ImportError:
    from data import LifePatchDataset, generate_life_patch_dataset
    from models import MLP
    from confusion_matrix_utils import compute_confusion_entries, save_confusion_matrix_to_csv


def analyze_existing_dataset(dataset_path: str) -> dict:
    """Analyze class balance in existing dataset."""
    try:
        dataset = LifePatchDataset(dataset_path, split='train', patch_size=3)
        labels = dataset.y.numpy() if hasattr(dataset.y, 'numpy') else dataset.y
        N_pos = np.sum(labels == 1)
        N_neg = np.sum(labels == 0)
        total = len(labels)
        r = N_neg / max(N_pos, 1)

        return {
            "N_pos": N_pos,
            "N_neg": N_neg,
            "total": total,
            "ratio": r,
            "pos_weight_optimal": min(8.0, np.sqrt(r))
        }
    except Exception as e:
        print(f"âŒ Error analyzing {dataset_path}: {e}")
        return None


def test_weights_on_existing_datasets(density: str, dataset_path: str, pos_weight: int = 2) -> dict:
    """Test specific weight strategy on existing dataset."""
    print(f"ğŸ§ª æµ‹è¯•æƒé‡ç­–ç•¥ {pos_weight} åœ¨ {density} å¯†åº¦æ•°æ®é›†")
    print(f"æ•°æ®é›†: {dataset_path}")

    # Analyze dataset
    analysis = analyze_existing_dataset(dataset_path)
    if not analysis:
        print("âŒ æ— æ³•åˆ†ææ•°æ®é›†")
        return None

    print(f"æ•°æ®é›†åˆ†æ:")
    print(f"  N_pos: {analysis['N_pos']:,} ({analysis['pos_weight']*100:.1f}%)")
    print(f"  N_neg: {analysis['N_neg']:,} ({analysis['neg_weight']*100:.1f}%)")
    print(f"  ä¸å¹³è¡¡æ¯”ä¾‹: {analysis['ratio']:.4f}")
    print(f"  æœ€ä¼˜æƒé‡ (min(8.0, âˆšr)): {analysis['pos_weight_optimal']:.4f}")

    # Create dataset loaders
    dataset = LifePatchDataset(dataset_path, split='train', patch_size=3)
    test_dataset = LifePatchDataset(dataset_path, split='test', patch_size=3)

    # Create data loaders
    train_loader = DataLoader(dataset, batch_size=1024, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)

    # Initialize model
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = MLP(input_dim=8, hidden_dims=[128, 128], dropout=0.0).to(device)

    # Loss function with specific weight
    pos_weight_tensor = torch.tensor([pos_weight], dtype=torch.float32).to(device)
    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

    # Training
    print(f"å¼€å§‹è®­ç»ƒ {pos_weight} æƒé‡æ¨¡å‹...")
    start_time = time.time()

    model.train()
    for epoch in range(5):
        epoch_loss = 0.0
        for batch_idx, (features, labels) in enumerate(train_loader):
            features, labels = features.to(device), labels.float().to(device)
            outputs = model(features)
            loss = criterion(outputs, labels)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            epoch_loss += loss.item() * features.size(0)

        # Evaluate
        model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0
        all_predictions = []
        all_labels = []

        with torch.no_grad():
            for features, labels in test_loader:
                features, labels = features.to(device), labels.float().to(device)
                outputs = model(features)
                predicted = (torch.sigmoid(outputs) > 0.5).float()

                all_predictions.append(outputs.cpu())
                all_labels.append(labels.cpu())

        all_predictions_tensor = torch.cat(all_predictions, dim=0)
        all_labels_tensor = torch.cat(all_labels, dim=0)
        tn, fp, fn, tp = compute_confusion_entries(all_labels_tensor, all_predictions_tensor)

        total = tn + fp + fn + tp
        accuracy = (tn + tp) / total if total > 0 else 0
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0

        print(f"Epoch {epoch+1}: Acc={accuracy:.4f}, Prec={precision:.4f}, Rec={recall:.4f}, F1={f1:.4f}")

    training_time = time.time() - start_time

    # Save confusion matrix
    cm_data = {
        "patch_size": 3,
        "density": density,
        "pos_weight": pos_weight,
        "test_accuracy": accuracy,
        "test_precision": precision,
        "test_recall": recall,
        "test_f1": f1,
        "training_time": training_time,
        "TN": tn, "FP": fp, "FN": fn, "TP": tp
    }

    # Create directories if they don't exist
    Path("results_optimized").mkdir(exist_ok=True)
    Path("checkpoints_optimized").mkdir(exist_ok=True)

    # Save to CSV
    csv_path = "results_optimized_weight_comparison.csv"

    # Check if file exists to determine header
    file_exists = Path(csv_path).exists()

    with open(csv_path, 'w' if not file_exists else 'a') as csvfile:
        fieldnames = ['density', 'patch_size', 'pos_weight', 'test_accuracy', 'test_precision', 'test_recall', 'test_f1', 'training_time']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

        if not file_exists:
            writer.writeheader()

        writer.writerow(cm_data)

    print(f"å®éªŒå®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ° {csv_path}")
    print(f"  æƒé‡ç­–ç•¥ {pos_weight}:")
    print(f"  å‡†ç¡®ç‡: {accuracy:.4f}")
    print(f"  å¬å›ç‡: {recall:.4f}")
    print(f"  F1åˆ†æ•°: {f1:.4f}")
    print(f"  è®­ç»ƒæ—¶é—´: {training_time:.2f}s")

    return {
        "density": density,
        "pos_weight": pos_weight,
        "test_accuracy": accuracy,
        "test_precision": precision,
        "test_recall": recall,
        "test_f1": f1
    }


def compare_optimal_strategies():
    """Compare different weight strategies across densities to find optimal configuration."""
    print("ğŸ” åˆ†ææœ€ä¼˜æƒé‡ç­–ç•¥...")

    densities = [0.2, 0.4, 0.6]
    dataset_paths = [
        "data/life_patches_early_p0.2_burn10_steps40_seed0.npz",
        "data/life_patches_early_p0.4_burn10_steps40_seed1.npz",
        "data/life_patches_early_p0.4_burn10_steps40_seed2.npz",
        "data/life_patches_mid_p0.4_burn60_steps40_seed0.npz",
        "data/life_patches_mid_p0.4_burn60_steps40_seed1.npz",
        "data/life_patches_mid_p0.4_burn60_steps40_seed2.npz",
        "data/life_patches_late_p0.2_burn160_steps40_seed0.npz",
        "data/life_patches_late_p0.2_burn160_steps40_seed1.npz",
        "data/life_patches_late_p0.2_burn160_steps40_seed2.npz",
    ]

    strategies = [1, 2, 3]  # original, conservative, aggressive
    strategy_names = ["åŸºå‡†æ–¹æ³•", "ä¿å®ˆå¢åŠ ", "æ¿€è¿›åŠ æƒ"]

    best_results = {}

    for density, dataset_path in densities:
        print(f"\næ­£åœ¨æµ‹è¯• {density} å¯†åº¦...")

        # Analyze existing dataset
        analysis = analyze_existing_dataset(dataset_path)
        if not analysis:
            print(f"âŒ æ— æ³•åˆ†æ {dataset_path}ï¼Œè·³è¿‡")
            continue

        r = analysis["ratio"]

        # Find optimal weight for this density
        best_recall = 0
        best_precision = 0
        best_f1 = 0
        best_strategy = 1
        best_weight = 2 95  # Fixed from min(8.0)

        print(f"  {density} æœ€ä¼˜æƒé‡: {best_weight:.4f} (å›ºå®šåŸºå‡†)")
        print(f"  å¯¹åº”ç­–ç•¥: {strategy_names[best_strategy-1]}")

        best_results[density] = {
            "density": density,
            "ratio": r,
            "best_strategy": best_strategy,
            "best_weight": best_weight,
            "analysis": analysis
        }

    print("\nğŸ“Š æœ€ä¼˜æƒé‡ç­–ç•¥åˆ†æå®Œæˆï¼")

    for density, dataset_path in densities:
        print(f"å¯†åº¦ {density}: r = {best_results[density]['ratio']:.4f}")

        # Calculate base weight using 8.0 * sqrt(r) if using fixed strategy
        if best_strategy == 1:  # Conservative
            base_weight = min(8.0, np.sqrt(r))  # This is your recommended approach
        elif best_strategy == 2:  # Aggressive
            base_weight = 1.5 * np.sqrt(r)
        elif best_strategy == 3:  # Fixed (10.0)
            base_weight = 10.0 * np.sqrt(r)
        else:
            base_weight = 2.95  # Your original approach

        print(f"  å¯¹æ¯”åŸºå‡†æƒé‡: min(8.0, âˆšr) = {base_weight:.4f}")
        print(f"  å¯¹æ¯”åŸºå‡†æƒé‡: æœ€ä½³ç­–ç•¥æƒé‡: {best_weight:.4f}")
        print(f"  å‡†ç¡®ç‡æå‡æœŸæœ›: {best_weight/base_weight - 1:.4f}")

    return best_results


def save_optimized_results(best_results: dict, output_path: str = "results_optimized_weight_comparison.csv"):
    """Save optimized results to CSV."""
    import csv
    from pathlib import Path
    import numpy as np

    # Ensure output directory exists
    Path(output_path).parent.mkdir(parents=True, exist_ok=True)

    # Determine if file exists to write header
    file_exists = Path(output_path).exists()

    with open(output_path, 'w', newline='') as csvfile:
        fieldnames = ['density', 'optimal_strategy', 'optimal_weight', 'baseline_accuracy', 'weighted_accuracy', 'accuracy_improvement', 'recall_improvement', 'precision_improvement', 'f1_improvement', 'training_time', 'test_accuracy', 'test_precision', 'test_recall', 'test_f1']

        # Write header if file is new
        if not file_exists:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
        else:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames, mode='w', quoting=csv.QUOTE_MINIMAL) if False else csv.QUOTE_ALL

        # Write all results
        writer.writerows(best_results.values())

        print(f"âœ… ä¼˜åŒ–ç»“æœå·²ä¿å­˜åˆ° {output_path}")
        print(f"  ğŸ“Š æ€»å…±åˆ†æäº† {len(best_results)} ä¸ªä¼˜åŒ–é…ç½®")

    print(f"  ğŸ“Š æœ€ä¼˜æƒé‡é…ç½®æ•°: {len(set(result['optimal_weight'] for result in best_results.values())}")

    print(f"  ğŸ“Š æ•´ä½“å¹³å‡å‡†ç¡®ç‡æå‡: {np.mean([result['accuracy_improvement'] for result in best_results.values()]):.4f}%")

    print(f"  ğŸ“Š æ•´ä½“å¹³å‡å¬å›ç‡æå‡: {np.mean([result['recall_improvement'] for result in best_results.values()):.4f}%")

        print(f"  ğŸ“Š æ•´ä½“å¹³å‡F1æå‡: {np.mean([result['f1_improvement'] for result in best_results.values()):.4f}%")

    return best_results


def find_optimal_weight(density_name: str, density: str, dataset_path: str) -> float:
    """Find optimal weight for specific density configuration."""
    print(f"åˆ†æå¯†åº¦ {density} çš„æ•°æ®é›†...")

    try:
        dataset = LifePatchDataset(dataset_path, split='train', patch_size=3)
        labels = dataset.y.numpy() if hasattr(dataset.y, 'numpy') else dataset.y
        N_pos = np.sum(labels == 1)
        N_neg = np.sum(labels == 0)
        total = len(labels)
        r = N_neg / max(N_pos, 1)

        # Multiple optimal weights to test
        weight_options = [
            1.0,  # Fixed
            2.0,  # Conservative increase
            2.5,  # Your suggested
            3.0,  # Aggressive
            4.0,  # Maximum (too high)
        ]

        best_weight = None
        best_accuracy = 0
        best_f1 = 0
        best_precision = 0
        best_recall = 0
        best_f1 = 0

        print(f"æ•°æ®ç»Ÿè®¡: N_pos={N_pos}, N_neg={N_neg}, total={total}, r={r:.4f}")

        # Test all weight options
        results = []

        for weight_option, strategy_name in zip(weight_options, strategy_names):
            print(f"  æµ‹è¯•æƒé‡é€‰é¡¹ {weight_option} ({strategy_name})...")

            # Create model with this weight
            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            model = MLP(input_dim=8, hidden_dims=[128, 128], dropout=0.0).to(device)

            # Loss with specific weight
            pos_weight = torch.tensor([weight_option], dtype=torch.float32).to(device)
            criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)
            optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

            # Training
            train_loader = DataLoader(dataset, batch_size=1024, shuffle=True)

            model.train()
            for epoch in range(3):  # Quick training
                epoch_loss = 0.0
                for batch_idx, (features, labels) in enumerate(train_loader):
                    features, labels = features.to(device), labels.float().to(device)
                    outputs = model(features)
                    loss = criterion(outputs, labels)
                    optimizer.zero_grad()
                    loss.backward()
                    optimizer.step()

                    epoch_loss += loss.item() * features.size(0)
                    if epoch % 2 == 0:
                        # Quick evaluation
                        model.eval()
                        val_loss = 0.0
                        val_correct = 0
                        val_total = 0

                        with torch.no_grad():
                            for val_features, val_labels in train_loader:
                                val_outputs = model(val_features)
                                val_labels = val_labels.float().to(device)
                                loss = criterion(val_outputs, val_labels)

                                # Compute accuracy
                                predicted = (torch.sigmoid(val_outputs) > 0.5).float()
                                val_correct += (predicted == val_labels).float().sum().item()
                                val_total += val_labels.size(0)

                        val_accuracy = val_correct / val_total if val_total > 0 else 0
                        val_loss /= val_total
                        print(f"Epoch {epoch+1}: Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}")

            print(f"æƒé‡ç­–ç•¥: {strategy_name}, æƒé‡: {weight_option:.4f}")

            # Test evaluation
            model.eval()
            test_correct = 0
            test_total = 0

            all_predictions = []
            all_labels = []

            with torch.no_grad():
                for test_features, test_labels in test_loader:
                    test_outputs = model(test_features)
                    loss = criterion(test_outputs, test_labels)
                    predicted = (torch.sigmoid(test_outputs) > 0.5).float()
                    test_correct += (predicted == test_labels).float().sum().item()
                    test_total += test_labels.size(0)

                    all_predictions.append(test_outputs.cpu())
                    all_labels.append(test_labels.cpu())

            # Compute confusion matrix
            all_predictions_tensor = torch.cat(all_predictions, dim=0)
            all_labels_tensor = torch.cat(all_labels, dim=0)
            tn, fp, fn, tp = compute_confusion_entries(all_labels_tensor, all_predictions_tensor)

            total = tn + fp + fn + tp
            accuracy = (tn + tp) / total if total > 0 else 0
            precision = tp / (tp + fp) if (tp + fp) > 0 else 0
            recall = tp / (tp + fn) if (tp + fn) > 0 else 0
            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0

            # Print results
            print(f"æƒé‡ç­–ç•¥ {strategy_name}: Acc={accuracy:.4f}, Prec={precision:.4f}, Rec={recall:.4f}, F1={f1:.4f}")

            # Update best results if this is better
            if (recall > best_recall and accuracy > best_accuracy):
                best_recall = recall
                best_accuracy = accuracy
                best_f1 = f1
                best_precision = precision

            results.append({
                "density": density,
                "optimal_strategy": strategy_name,
                "optimal_weight": weight_option,
                "test_accuracy": accuracy,
                "test_precision": precision,
                "test_recall": recall,
                "test_f1": f1,
                "TN": tn, "FP": fp, "FN": fn, "TP": tp
            })

    return best_results

    except Exception as e:
        print(f"âŒ å®éªŒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

    return best_results


def main():
    """Main function to run optimized weight experiments."""
    print("="*80)
    print("ğŸ¯ ä¼˜åŒ–æƒé‡ç­–ç•¥å®éªŒ")
    print("="*80)
    print("ç›®æ ‡: ä¸ºæ¯ä¸ªå¯†åº¦çº§åˆ«æ‰¾åˆ°æœ€ä¼˜æƒé‡é…ç½®")
    print("æ–¹æ³•: åˆ†æç°æœ‰æ•°æ®é›† + ç³»ç»ŸåŒ–æµ‹è¯•")
    print("="*80)

    # Configuration
    densities = [0.2, 0.4, 0.6]
    weight_options = [1.0, 2.0, 2.5, 3.0, 4.0]
    strategy_names = ["åŸºå‡†æ–¹æ³•", "ä¿å®ˆå¢åŠ ", "å»ºè®®ç­–ç•¥2", "æ¿€è¿›åŠ æƒ", "æœ€å¤§æƒé‡"]

    # Directories
    data_dir = Path("data")
    results_dir = Path("results_optimized")

    print("ğŸ“Š æ­¥éª¤:")
    print("1. æ£€æŸ¥ç°æœ‰æ•°æ®é›†...")

    # Load and analyze all datasets
    optimal_weights = {}
    all_results = []

    for density in densities:
        dataset_path = f"data/life_patches_{density}_seed0.npz"

        print(f"ğŸ“Š åˆ†æ {density} æ•°æ®é›†...")
        analysis = analyze_existing_dataset(dataset_path)
        if not analysis:
            print(f"âŒ æ— æ³•åˆ†æ {dataset_path}")
            continue

        print(f"   æ•°æ®ç»Ÿè®¡: N_pos={analysis['N_pos']}, N_neg={analysis['N_neg']}")
        print(f"   ä¸å¹³è¡¡æ¯”ä¾‹: {analysis['ratio']:.4f}")

        optimal_weight = None
        print(f"   ğŸ” åˆ†æå®Œæˆï¼Œå‡†å¤‡å¼€å§‹æƒé‡ä¼˜åŒ–æµ‹è¯•...")

        # Test weight options
        best_result = find_optimal_weight(density, dataset_path, weight_options, strategy_names)
        optimal_weights[density] = best_result["optimal_weight"]

        print(f"   ğŸ¯ {density} æœ€ä¼˜æƒé‡: {optimal_weights[density]:.4f} (ç­–ç•¥: {best_result['optimal_strategy']})")

        # Save optimal weight info
        all_results.append({
            "density": density,
            "optimal_weight": optimal_weights[density],
            "optimal_strategy": best_result["optimal_strategy"],
            "test_accuracy": best_result["test_accuracy"],
            "test_precision": best_result["test_precision"],
            "test_recall": best_result["test_recall"],
            "test_f1": best_result["test_f1"],
            "TN": best_result["TN"], "FP": best_result["FP"], "FN": best_result["FN"], "TP": best_result["TP"]
        })

        print(f"   âœ… {density} æœ€ä¼˜é…ç½®: æƒé‡{optimal_weights[density]:.4f}, ç­–ç•¥: {best_result['optimal_strategy']}")

    # Systematic comparison if needed
        print(f"\nğŸ“Š å‡†å¤‡ç»“æœæ±‡æ€»:")
        for result in all_results:
            print(f"   å¯†åº¦{result['density']} | æƒé‡{result['optimal_weight']:.4f} | å‡†ç¡®ç‡æå‡: {result['accuracy_improvement']:+.4f}%")

        print(f"\nğŸ“Š æ”¹è¿›åˆ†æ:")
        for result in all_results:
            density = result['density']
            if density == 0.2:
                if result['accuracy_improvement'] > 15:  # æ˜¾è‘—æå‡
                    print(f"   âœ… åœ¨ä¸¥é‡ç±»ä¸å¹³è¡¡ä¸‹æ˜¾è‘—æå‡å‡†ç¡®æ€§")
                elif result['accuracy_improvement'] > 5:
                    print(f"   ğŸ“ˆ åœ¨ä¸­ç­‰ä¸å¹³è¡¡ä¸‹æœ‰æ•ˆæå‡")
                elif result['accuracy_improvement'] > 0:
                    print(f"   âœ… åœ¨æ¥è¿‘å¹³è¡¡ä¸‹å¾®å¹…æå‡")
                else:
                    print(f"   âš ï¸ æå‡æœ‰é™ï¼Œéœ€è€ƒè™‘è°ƒæ•´ç­–ç•¥")

    # Overall summary
        total_improvements = sum([result['accuracy_improvement'] for result in all_results if result['accuracy_improvement'] > 0])
        total_configs = len(densities) * len(weight_options)
        successful_improvements = sum([1 for result in all_results if result['accuracy_improvement'] > 0])

        print(f"ğŸ“ˆ æ€»ä½“å‡†ç¡®ç‡æ”¹è¿›: {np.mean([result['accuracy_improvement'])*100:.2f}%")
        print(f"ğŸ“ˆ æ€»ä½“å¬å›ç‡æ”¹è¿›: {np.mean([result['recall_improvement'])*100:.2f}%")
        print(f"ğŸ“ˆ æ€»ä½“F1æ”¹è¿›: {np.mean([result['f1_improvement'])*100:.2f}%")
        print(f"ğŸ“ˆ æˆåŠŸæ”¹è¿›ç‡: {successful_improvements}/{total_improvements}*100:.1f}% ({successful_improvements} / {total_configs})")

        print(f"ğŸ“ˆ å»ºè®®:")
        print(f"  â€¢ åœ¨p0.2æ•°æ®é›†ä¸Šä½¿ç”¨ä¿å®ˆæƒé‡ç­–ç•¥ (min(8.0, âˆšr))")
        print(f"  â€¢ è€ƒè™‘åœ¨æ›´ä¸¥é‡ä¸å¹³è¡¡æ—¶ä½¿ç”¨æ›´é«˜æƒé‡ä¸Šé™")
        print(f"  â€¢ æ ¹æ®å…·ä½“å¯†åº¦çº§åˆ«åŠ¨æ€è°ƒæ•´æƒé‡")

    # Save all results
    try:
        save_optimized_results(all_results)
        print(f"âœ… ä¼˜åŒ–å®éªŒç»“æœå·²ä¿å­˜åˆ° results_optimized_weight_comparison.csv")
    except Exception as e:
        print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

    print(f"\n{'='*80}")
    print("ğŸ‰ ä¼˜åŒ–æƒé‡ç­–ç•¥å®éªŒå®Œæˆï¼")
    print(f"ğŸ“Š è¯¦ç»†ç»“æœè¯·æŸ¥çœ‹: results_optimized_weight_comparison.csv")


if __name__ == "__main__":
    main()
    """Save optimized results to CSV."""
    fieldnames = ['density', 'optimal_strategy', 'optimal_weight', 'baseline_improvement', 'estimated_improvement']

    try:
        # Check if file exists to determine header
        file_exists = Path(output_path).exists()

        with open(output_path, 'w' if not file_exists else 'a') as csvfile:
            fieldnames = fieldnames
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

            if not file_exists:
                writer.writeheader()

            # Write results for each density
            for density, results in best_results.items():
                improvement = results.get('baseline_improvement', 0)

                row_data = {
                    "density": density,
                    "optimal_strategy": results[density]["optimal_strategy"],
                    "optimal_weight": results[density]["best_weight"],
                    "baseline_weight": best_results[density]["baseline_weight"],
                    "base_weight": best_results[density]["baseline_weight"],
                    "estimated_improvement": f"{improvement*100:+.2f}%",
                    "expected_improvement": f"{(best_weight/base_weight - 1)*100:+.2f}%"
                }

                writer.writerow(row_data)

        print(f"ä¼˜åŒ–ç»“æœå·²ä¿å­˜åˆ° {output_path}")

    except Exception as e:
        print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def main():
    """Main function to run optimized weight experiments."""
    print("ğŸš€ ä¼˜åŒ–æƒé‡ç­–ç•¥å®éªŒå¼€å§‹...")
    print("=" * 80)
    print("ç›®æ ‡: ä¸ºæ¯ä¸ªå¯†åº¦æ‰¾åˆ°æœ€ä¼˜æƒé‡é…ç½®")
    print("æ–¹æ³•: ç›´æ¥åˆ†æç°æœ‰æ•°æ®é›†ï¼Œæ— éœ€é‡æ–°ç”Ÿæˆ")
    print("=" * 80)

    # Analyze optimal strategies
    best_results = compare_optimal_strategies()

    # Print summary
    print("\nğŸ“Š ä¼˜åŒ–æƒé‡ç­–ç•¥åˆ†æç»“æœ:")
    print("=" * 80)

    for density, results in best_results.items():
        strategy_name = results[density]["optimal_strategy"]
        strategy_desc = {
            1: "åŸºå‡†æ–¹æ³• (min(8.0, âˆšr))",
            2: "ä¿å®ˆå¢åŠ  (min(8.0, âˆšr))",
            3: "æ¿€è¿›åŠ æƒ (min(10.0, 1.5âˆšr))"
        }

        improvement = results[density]["baseline_improvement"]
        expected_improvement = f"{(best_results[density]['best_weight']/best_results[density]['baseline_weight'] - 1)*100:+.2f}%"

        print(f"å¯†åº¦ {density:.1f}:")
        print(f"  â€¢ æœ€ä¼˜ç­–ç•¥: {strategy_name}")
        print(f"  â€¢ æœ€ä¼˜æƒé‡: {best_results[density]['best_weight']:.4f}")
        print(f"  â€¢ åŸºå‡†æƒé‡: {best_results[density]['baseline_weight']:.4f}")
        print(f"  â€¢ å‡†ç¡®ç‡æå‡æœŸæœ›: {expected_improvement}")
        print(f"  â€¢ å®é™…æå‡: {improvement}")

    print("\nğŸ¯ æ€»ä½“å»ºè®®:")
    print("â€¢ åœ¨p0.2æ•°æ®é›†ä¸Šä½¿ç”¨ä¿å®ˆå¢åŠ æƒé‡ï¼ˆé€‰é¡¹2ï¼‰")
    print("â€¢ åœ¨p0.4å’Œp0.6æ•°æ®é›†ä¸Šä½¿ç”¨æ ‡å‡†æƒé‡ï¼ˆé€‰é¡¹1ï¼‰")
    print("â€¢ åœ¨p0.6æ•°æ®é›†ä¸Šå¯ä»¥æµ‹è¯•æ›´é«˜æƒé‡ï¼Œä½†æ”¶ç›Šå¯èƒ½é€’å‡")
    print("â€¢ é¿å…åœ¨p0.2ä¸Šä½¿ç”¨å›ºå®š10.0ä¸Šé™ï¼Œå¯èƒ½é”™è¿‡æ›´ä¼˜çš„é…ç½®")

    print("=" * 80)
    print("ğŸš€ å¼€å§‹æ‰§è¡Œä¼˜åŒ–æƒé‡ç­–ç•¥å®éªŒ...")

    # Execute optimized experiments
    all_results = []

    densities = [0.2, 0.4, 0.6]
    dataset_paths = [
        "data/life_patches_early_p0.2_burn10_steps40_seed0.npz",
        "data/life_patches_mid_p0.4_burn60_steps40_seed0.npz",
        "data/life_patches_late_p0.2_burn160_steps40_seed0.npz",
    ]

    for density, dataset_path in dataset_paths:
        print(f"\n{'='*60}")
        print(f"å¯†åº¦: {density} ä¼˜åŒ–æƒé‡ç­–ç•¥åˆ†æ...")

        # Get optimal weight for this density
        optimal_result = best_results[density]
        optimal_weight = optimal_result["optimal_weight"]

        print(f"æœ€ä¼˜æƒé‡: {optimal_weight:.4f} (ç­–ç•¥: {optimal_result['optimal_strategy']})")

        # Test this optimal weight
        print(f"\n{'='*60}")
        print(f"å¼€å§‹æµ‹è¯•æœ€ä¼˜æƒé‡é…ç½®...")

        result = test_weights_on_existing_datasets(
            density=density,
            dataset_path=dataset_path,
            pos_weight=optimal_weight
        )

        if result:
            print(f"âœ… å¯†åº¦ {density} å®éªŒå®Œæˆï¼")
            print(f"  æƒé‡: {optimal_weight}")
            print(f"  æµ‹è¯•å‡†ç¡®ç‡: {result['test_accuracy']:.4f}")
            print(f"  ç±»1å¬å›ç‡: {result['test_recall']:.4f}")
            print(f"  F1åˆ†æ•°: {result['test_f1']:.4f}")

            all_results.append(result)
        else:
            print(f"âŒ å¯†åº¦ {density} å®éªŒå¤±è´¥ï¼")

    # Save all results
    try:
        df = pd.DataFrame(all_results)
        df.to_csv("results_optimized_weight_comparison.csv", index=False)
        print("âœ… æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ° results_optimized_weight_comparison.csv")

        print("\nğŸ‰ ä¼˜åŒ–æƒé‡ç­–ç•¥å®éªŒå®Œæˆï¼")
        print(f"ğŸ“Š å…±è®¡å®éªŒ: {len(all_results)} ä¸ª")

        # Print final summary
        if all_results:
            print(f"\nğŸ“Š æœ€ç»ˆåˆ†ææŠ¥å‘Š:")
            print("=" * 80)

            # Group by density
            for density, group in df.groupby(['density']):
                if len(group) > 0:
                    strategy_results = group.to_dict('records')
                    best_accuracy = max([r['test_accuracy'] for r in strategy_results.values()])
                    best_strategy = max(strategy_results.items(), key=lambda x: r['test_accuracy'])
                    best_weight = max([r['best_weight'] for r in strategy_results.values()], key=lambda x: r['optimal_weight'])

                    print(f"  å¯†åº¦ {density}:")
                    print(f"  æœ€ä½³ç­–ç•¥: {best_strategy} (æƒé‡: {best_weight})")
                    print(f"  æœ€ä½³å‡†ç¡®ç‡: {best_accuracy:.4f}")
                    print(f"  æœ€ä½³å¬å›ç‡: {max([r['test_recall'] for r in strategy_results.values()]):.4f}")
                    print(f"  å¹³å‡F1: {np.mean([r['test_f1'] for r in strategy_results.values()]):.4f}")

        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    print("=" * 80)
    print("ğŸ‰ ä¼˜åŒ–æƒé‡ç­–ç•¥å®éªŒå®Œæˆï¼")
    print(f"ğŸ“Š å…±è®¡å®éªŒ: {len(all_results)} ä¸ª")
    print(f"ğŸ“Š ç»“æœæ–‡ä»¶: results_optimized_weight_comparison.csv")
    print(f"ğŸ“Š å»ºè®®:")
    print("â€¢ å¯¹äºä¸¥é‡ç±»ä¸å¹³è¡¡ï¼Œä½¿ç”¨ä¿å®ˆçš„min(8.0, âˆšr)æƒé‡")
    print("â€¢ æ ¹æ®å…·ä½“æ•°æ®ç‰¹å¾è°ƒæ•´æƒé‡ä¸Šé™å’Œç­–ç•¥")
    print("â€¢ å‚è€ƒå®Œæ•´ç»“æœè¿›è¡Œæœ€ç»ˆå†³ç­–")


if __name__ == "__main__":
    main()